{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# model explanation\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "# catboost model\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# import function\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "import os\n",
    "\n",
    "# for warning ignore\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path of the processed data\n",
    "processed_data_path = os.path.join(os.path.pardir, 'data', 'processed')\n",
    "train_file_path = os.path.join(processed_data_path, 'train.csv')\n",
    "test_file_path = os.path.join(processed_data_path, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_file_path)\n",
    "test_df = pd.read_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611772, 35)\n",
      "(611772,)\n"
     ]
    }
   ],
   "source": [
    "# Create independent and Dependent features\n",
    "columns = train_df.columns.tolist()\n",
    "# Filter the columns to remove data we do not want\n",
    "columns = [c for c in columns if c not in [\"Label\"]]\n",
    "# Store the variable we are predicting\n",
    "target = \"Label\"\n",
    "# Define a random state\n",
    "state = np.random.RandomState(42)\n",
    "X = train_df[columns]\n",
    "y = train_df[target]\n",
    "\n",
    "# print the shapes of X and Y\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_test_data = test_df.drop([\"ID X PCODE\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "model_lr_1 = LogisticRegression(random_state=0)\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission_file(model, filename):\n",
    "    # converting to the matrix\n",
    "    test_X = preprocessed_test_data.as_matrix().astype('float')\n",
    "    # make predictions\n",
    "    predictions = model.predict(test_X)\n",
    "    # submission dataframe\n",
    "    df_submission = pd.DataFrame({'ID X PCODE': test_df[\"ID X PCODE\"], 'Label' : predictions})\n",
    "    # submission file\n",
    "    submission_data_path = os.path.join(os.path.pardir, 'data', 'external')\n",
    "    submission_file_path = os.path.join(submission_data_path, filename)\n",
    "    # write to the file\n",
    "    df_submission.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 4)\n",
    "scores = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "    \n",
    "# Train the model\n",
    "trained_model_lr_1 = model_lr_1.fit(X_train, y_train)\n",
    "y_pred = trained_model_lr_1.predict(X_test)\n",
    "\n",
    "# Score the model on the validation data\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "scores.append(score)\n",
    "mean_score = np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores of the model: 0.89\n",
      "\n",
      " Classification report of the model\n",
      "--------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     54541\n",
      "           1       0.23      0.02      0.03      6636\n",
      "\n",
      "    accuracy                           0.89     61177\n",
      "   macro avg       0.56      0.50      0.49     61177\n",
      "weighted avg       0.82      0.89      0.84     61177\n",
      "\n",
      "\n",
      " Confusion Matrix of the model\n",
      "--------------------------------------\n",
      "[[54170   371]\n",
      " [ 6527   109]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy scores of the model: {:.2f}'.format(mean_score))\n",
    "print('\\n Classification report of the model')\n",
    "print('--------------------------------------')\n",
    "print(report)\n",
    "print('\\n Confusion Matrix of the model')\n",
    "print('--------------------------------------')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_submission_file(trained_model_lr_1, \"2.0-stratified logistic regression.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':[1.0,10.0,50.0,100.0,1000.0], 'penalty' : ['l1', 'l2']}\n",
    "clf = GridSearchCV(model_lr_1, param_grid=parameters, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 4)\n",
    "scores = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "    \n",
    "# Train the model\n",
    "trained_model_lr_1 = clf.fit(X_train, y_train)\n",
    "y_pred = trained_model_lr_1.predict(X_test)\n",
    "\n",
    "# Score the model on the validation data\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "scores.append(score)\n",
    "mean_score = np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores of the model: 0.89\n",
      "\n",
      " Classification report of the model\n",
      "--------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     54541\n",
      "           1       0.23      0.01      0.01      6636\n",
      "\n",
      "    accuracy                           0.89     61177\n",
      "   macro avg       0.56      0.50      0.48     61177\n",
      "weighted avg       0.82      0.89      0.84     61177\n",
      "\n",
      "\n",
      " Confusion Matrix of the model\n",
      "--------------------------------------\n",
      "[[54414   127]\n",
      " [ 6598    38]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy scores of the model: {:.2f}'.format(mean_score))\n",
    "print('\\n Classification report of the model')\n",
    "print('--------------------------------------')\n",
    "print(report)\n",
    "print('\\n Confusion Matrix of the model')\n",
    "print('--------------------------------------')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 4)\n",
    "scores = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "    \n",
    "# Train the model\n",
    "trained_xgb_1 = xgb.fit(X_train, y_train)\n",
    "y_pred = trained_xgb_1.predict(X_test)\n",
    "\n",
    "# Score the model on the validation data\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "scores.append(score)\n",
    "mean_score = np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores of the model: 0.96\n",
      "\n",
      " Classification report of the model\n",
      "--------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     54541\n",
      "           1       0.86      0.77      0.81      6636\n",
      "\n",
      "    accuracy                           0.96     61177\n",
      "   macro avg       0.92      0.88      0.90     61177\n",
      "weighted avg       0.96      0.96      0.96     61177\n",
      "\n",
      "\n",
      " Confusion Matrix of the model\n",
      "--------------------------------------\n",
      "[[53730   811]\n",
      " [ 1535  5101]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy scores of the model: {:.2f}'.format(mean_score))\n",
    "print('\\n Classification report of the model')\n",
    "print('--------------------------------------')\n",
    "print(report)\n",
    "print('\\n Confusion Matrix of the model')\n",
    "print('--------------------------------------')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = preprocessed_test_data.as_matrix().astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission_file(model, filename):\n",
    "    # converting to the matrix\n",
    "    test_X = preprocessed_test_data\n",
    "    # make predictions\n",
    "    predictions = model.predict(test_X)\n",
    "    # submission dataframe\n",
    "    df_submission = pd.DataFrame({'ID X PCODE': test_df[\"ID X PCODE\"], 'Label' : predictions})\n",
    "    # submission file\n",
    "    submission_data_path = os.path.join(os.path.pardir, 'data', 'external')\n",
    "    submission_file_path = os.path.join(submission_data_path, filename)\n",
    "    # write to the file\n",
    "    df_submission.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_submission_file(trained_xgb_1, \"stratified_xgboost1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_xgb = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1.0, gamma=1,\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
    "              min_child_weight=5, missing=None, n_estimators=100, n_jobs=1,\n",
    "              nthread=None, objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=None, subsample=0.8, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 4)\n",
    "scores = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "    \n",
    "# Train the model\n",
    "trained_xgb_2 = tuned_xgb.fit(X_train, y_train)\n",
    "y_pred = trained_xgb_2.predict(X_test)\n",
    "\n",
    "# Score the model on the validation data\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "scores.append(score)\n",
    "mean_score = np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores of the model: 0.96\n",
      "\n",
      " Classification report of the model\n",
      "--------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     54541\n",
      "           1       0.86      0.74      0.80      6636\n",
      "\n",
      "    accuracy                           0.96     61177\n",
      "   macro avg       0.92      0.86      0.89     61177\n",
      "weighted avg       0.96      0.96      0.96     61177\n",
      "\n",
      "\n",
      " Confusion Matrix of the model\n",
      "--------------------------------------\n",
      "[[53762   779]\n",
      " [ 1740  4896]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy scores of the model: {:.2f}'.format(mean_score))\n",
    "print('\\n Classification report of the model')\n",
    "print('--------------------------------------')\n",
    "print(report)\n",
    "print('\\n Confusion Matrix of the model')\n",
    "print('--------------------------------------')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_submission_file(trained_xgb_1, \"xgboost_submission4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_PARAMS = {'learning_rate': 0.4,\n",
    "                'max_depth': 15,\n",
    "                'num_leaves': 32,\n",
    "                'feature_fraction': 0.8,\n",
    "                'subsample': 0.2}\n",
    "\n",
    "FIXED_PARAMS={'objective': 'binary',\n",
    "             'metric': 'auc',\n",
    "             'is_unbalance':True,\n",
    "             'bagging_freq':5,\n",
    "             'boosting':'dart',\n",
    "             'num_boost_round':300,\n",
    "             'early_stopping_rounds':30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 53176, number of negative: 436241\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.117939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 640\n",
      "[LightGBM] [Info] Number of data points in the train set: 489417, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.108652 -> initscore=-2.104588\n",
      "[LightGBM] [Info] Start training from score -2.104588\n",
      "[1]\tvalid's auc: 0.932586\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid's auc: 0.949224\n",
      "[3]\tvalid's auc: 0.948716\n",
      "[4]\tvalid's auc: 0.950446\n",
      "[5]\tvalid's auc: 0.950827\n",
      "[6]\tvalid's auc: 0.957779\n",
      "[7]\tvalid's auc: 0.958199\n",
      "[8]\tvalid's auc: 0.958221\n",
      "[9]\tvalid's auc: 0.959992\n",
      "[10]\tvalid's auc: 0.96037\n",
      "[11]\tvalid's auc: 0.961388\n",
      "[12]\tvalid's auc: 0.961773\n",
      "[13]\tvalid's auc: 0.961662\n",
      "[14]\tvalid's auc: 0.96178\n",
      "[15]\tvalid's auc: 0.9623\n",
      "[16]\tvalid's auc: 0.963788\n",
      "[17]\tvalid's auc: 0.964349\n",
      "[18]\tvalid's auc: 0.964577\n",
      "[19]\tvalid's auc: 0.964561\n",
      "[20]\tvalid's auc: 0.965007\n",
      "[21]\tvalid's auc: 0.965105\n",
      "[22]\tvalid's auc: 0.96569\n",
      "[23]\tvalid's auc: 0.96598\n",
      "[24]\tvalid's auc: 0.966181\n",
      "[25]\tvalid's auc: 0.966354\n",
      "[26]\tvalid's auc: 0.966978\n",
      "[27]\tvalid's auc: 0.967762\n",
      "[28]\tvalid's auc: 0.967991\n",
      "[29]\tvalid's auc: 0.968302\n",
      "[30]\tvalid's auc: 0.968732\n",
      "[31]\tvalid's auc: 0.969036\n",
      "[32]\tvalid's auc: 0.969269\n",
      "[33]\tvalid's auc: 0.969397\n",
      "[34]\tvalid's auc: 0.969524\n",
      "[35]\tvalid's auc: 0.969792\n",
      "[36]\tvalid's auc: 0.969905\n",
      "[37]\tvalid's auc: 0.970129\n",
      "[38]\tvalid's auc: 0.970209\n",
      "[39]\tvalid's auc: 0.970345\n",
      "[40]\tvalid's auc: 0.970603\n",
      "[41]\tvalid's auc: 0.97075\n",
      "[42]\tvalid's auc: 0.970901\n",
      "[43]\tvalid's auc: 0.971077\n",
      "[44]\tvalid's auc: 0.971304\n",
      "[45]\tvalid's auc: 0.971402\n",
      "[46]\tvalid's auc: 0.971484\n",
      "[47]\tvalid's auc: 0.97161\n",
      "[48]\tvalid's auc: 0.971784\n",
      "[49]\tvalid's auc: 0.97189\n",
      "[50]\tvalid's auc: 0.972031\n",
      "[51]\tvalid's auc: 0.972132\n",
      "[52]\tvalid's auc: 0.972179\n",
      "[53]\tvalid's auc: 0.972231\n",
      "[54]\tvalid's auc: 0.9723\n",
      "[55]\tvalid's auc: 0.972426\n",
      "[56]\tvalid's auc: 0.972507\n",
      "[57]\tvalid's auc: 0.972587\n",
      "[58]\tvalid's auc: 0.972619\n",
      "[59]\tvalid's auc: 0.972691\n",
      "[60]\tvalid's auc: 0.972758\n",
      "[61]\tvalid's auc: 0.972819\n",
      "[62]\tvalid's auc: 0.972864\n",
      "[63]\tvalid's auc: 0.972912\n",
      "[64]\tvalid's auc: 0.972962\n",
      "[65]\tvalid's auc: 0.973009\n",
      "[66]\tvalid's auc: 0.973086\n",
      "[67]\tvalid's auc: 0.973115\n",
      "[68]\tvalid's auc: 0.973185\n",
      "[69]\tvalid's auc: 0.973231\n",
      "[70]\tvalid's auc: 0.973254\n",
      "[71]\tvalid's auc: 0.973291\n",
      "[72]\tvalid's auc: 0.973314\n",
      "[73]\tvalid's auc: 0.97337\n",
      "[74]\tvalid's auc: 0.973405\n",
      "[75]\tvalid's auc: 0.973491\n",
      "[76]\tvalid's auc: 0.973569\n",
      "[77]\tvalid's auc: 0.973612\n",
      "[78]\tvalid's auc: 0.973642\n",
      "[79]\tvalid's auc: 0.973724\n",
      "[80]\tvalid's auc: 0.973733\n",
      "[81]\tvalid's auc: 0.973805\n",
      "[82]\tvalid's auc: 0.973823\n",
      "[83]\tvalid's auc: 0.973856\n",
      "[84]\tvalid's auc: 0.973917\n",
      "[85]\tvalid's auc: 0.973919\n",
      "[86]\tvalid's auc: 0.973936\n",
      "[87]\tvalid's auc: 0.974009\n",
      "[88]\tvalid's auc: 0.97401\n",
      "[89]\tvalid's auc: 0.97402\n",
      "[90]\tvalid's auc: 0.974052\n",
      "[91]\tvalid's auc: 0.974054\n",
      "[92]\tvalid's auc: 0.9741\n",
      "[93]\tvalid's auc: 0.974134\n",
      "[94]\tvalid's auc: 0.97414\n",
      "[95]\tvalid's auc: 0.974203\n",
      "[96]\tvalid's auc: 0.974226\n",
      "[97]\tvalid's auc: 0.974275\n",
      "[98]\tvalid's auc: 0.974304\n",
      "[99]\tvalid's auc: 0.974326\n",
      "[100]\tvalid's auc: 0.974361\n",
      "[101]\tvalid's auc: 0.974364\n",
      "[102]\tvalid's auc: 0.9744\n",
      "[103]\tvalid's auc: 0.974419\n",
      "[104]\tvalid's auc: 0.974416\n",
      "[105]\tvalid's auc: 0.974419\n",
      "[106]\tvalid's auc: 0.974463\n",
      "[107]\tvalid's auc: 0.97447\n",
      "[108]\tvalid's auc: 0.97447\n",
      "[109]\tvalid's auc: 0.974482\n",
      "[110]\tvalid's auc: 0.974484\n",
      "[111]\tvalid's auc: 0.974478\n",
      "[112]\tvalid's auc: 0.974489\n",
      "[113]\tvalid's auc: 0.974556\n",
      "[114]\tvalid's auc: 0.974595\n",
      "[115]\tvalid's auc: 0.974625\n",
      "[116]\tvalid's auc: 0.974644\n",
      "[117]\tvalid's auc: 0.974703\n",
      "[118]\tvalid's auc: 0.974779\n",
      "[119]\tvalid's auc: 0.974814\n",
      "[120]\tvalid's auc: 0.974835\n",
      "[121]\tvalid's auc: 0.974849\n",
      "[122]\tvalid's auc: 0.97485\n",
      "[123]\tvalid's auc: 0.974876\n",
      "[124]\tvalid's auc: 0.974921\n",
      "[125]\tvalid's auc: 0.974956\n",
      "[126]\tvalid's auc: 0.974978\n",
      "[127]\tvalid's auc: 0.974982\n",
      "[128]\tvalid's auc: 0.974987\n",
      "[129]\tvalid's auc: 0.97502\n",
      "[130]\tvalid's auc: 0.975025\n",
      "[131]\tvalid's auc: 0.975055\n",
      "[132]\tvalid's auc: 0.975059\n",
      "[133]\tvalid's auc: 0.975076\n",
      "[134]\tvalid's auc: 0.975089\n",
      "[135]\tvalid's auc: 0.975116\n",
      "[136]\tvalid's auc: 0.975119\n",
      "[137]\tvalid's auc: 0.975117\n",
      "[138]\tvalid's auc: 0.975172\n",
      "[139]\tvalid's auc: 0.975184\n",
      "[140]\tvalid's auc: 0.975203\n",
      "[141]\tvalid's auc: 0.975235\n",
      "[142]\tvalid's auc: 0.975242\n",
      "[143]\tvalid's auc: 0.975261\n",
      "[144]\tvalid's auc: 0.975284\n",
      "[145]\tvalid's auc: 0.975282\n",
      "[146]\tvalid's auc: 0.975277\n",
      "[147]\tvalid's auc: 0.975276\n",
      "[148]\tvalid's auc: 0.975282\n",
      "[149]\tvalid's auc: 0.975286\n",
      "[150]\tvalid's auc: 0.975288\n",
      "[151]\tvalid's auc: 0.975284\n",
      "[152]\tvalid's auc: 0.975286\n",
      "[153]\tvalid's auc: 0.975281\n",
      "[154]\tvalid's auc: 0.975292\n",
      "[155]\tvalid's auc: 0.975308\n",
      "[156]\tvalid's auc: 0.975328\n",
      "[157]\tvalid's auc: 0.975344\n",
      "[158]\tvalid's auc: 0.975346\n",
      "[159]\tvalid's auc: 0.975346\n",
      "[160]\tvalid's auc: 0.975346\n",
      "[161]\tvalid's auc: 0.975352\n",
      "[162]\tvalid's auc: 0.975362\n",
      "[163]\tvalid's auc: 0.975407\n",
      "[164]\tvalid's auc: 0.975409\n",
      "[165]\tvalid's auc: 0.975415\n",
      "[166]\tvalid's auc: 0.975422\n",
      "[167]\tvalid's auc: 0.975425\n",
      "[168]\tvalid's auc: 0.975488\n",
      "[169]\tvalid's auc: 0.9755\n",
      "[170]\tvalid's auc: 0.97553\n",
      "[171]\tvalid's auc: 0.975533\n",
      "[172]\tvalid's auc: 0.97553\n",
      "[173]\tvalid's auc: 0.975528\n",
      "[174]\tvalid's auc: 0.975545\n",
      "[175]\tvalid's auc: 0.975579\n",
      "[176]\tvalid's auc: 0.975575\n",
      "[177]\tvalid's auc: 0.975579\n",
      "[178]\tvalid's auc: 0.975614\n",
      "[179]\tvalid's auc: 0.975622\n",
      "[180]\tvalid's auc: 0.975635\n",
      "[181]\tvalid's auc: 0.975634\n",
      "[182]\tvalid's auc: 0.975633\n",
      "[183]\tvalid's auc: 0.975642\n",
      "[184]\tvalid's auc: 0.975642\n",
      "[185]\tvalid's auc: 0.975652\n",
      "[186]\tvalid's auc: 0.975655\n",
      "[187]\tvalid's auc: 0.975665\n",
      "[188]\tvalid's auc: 0.975664\n",
      "[189]\tvalid's auc: 0.975667\n",
      "[190]\tvalid's auc: 0.975666\n",
      "[191]\tvalid's auc: 0.975667\n",
      "[192]\tvalid's auc: 0.975679\n",
      "[193]\tvalid's auc: 0.975682\n",
      "[194]\tvalid's auc: 0.975707\n",
      "[195]\tvalid's auc: 0.97574\n",
      "[196]\tvalid's auc: 0.97574\n",
      "[197]\tvalid's auc: 0.975734\n",
      "[198]\tvalid's auc: 0.97574\n",
      "[199]\tvalid's auc: 0.975738\n",
      "[200]\tvalid's auc: 0.975744\n",
      "[201]\tvalid's auc: 0.975749\n",
      "[202]\tvalid's auc: 0.975752\n",
      "[203]\tvalid's auc: 0.975752\n",
      "[204]\tvalid's auc: 0.975759\n",
      "[205]\tvalid's auc: 0.975773\n",
      "[206]\tvalid's auc: 0.97578\n",
      "[207]\tvalid's auc: 0.975789\n",
      "[208]\tvalid's auc: 0.975816\n",
      "[209]\tvalid's auc: 0.975816\n",
      "[210]\tvalid's auc: 0.97582\n",
      "[211]\tvalid's auc: 0.97582\n",
      "[212]\tvalid's auc: 0.975822\n",
      "[213]\tvalid's auc: 0.975921\n",
      "[214]\tvalid's auc: 0.975927\n",
      "[215]\tvalid's auc: 0.975942\n",
      "[216]\tvalid's auc: 0.975954\n",
      "[217]\tvalid's auc: 0.97598\n",
      "[218]\tvalid's auc: 0.976002\n",
      "[219]\tvalid's auc: 0.976009\n",
      "[220]\tvalid's auc: 0.976012\n",
      "[221]\tvalid's auc: 0.976029\n",
      "[222]\tvalid's auc: 0.976068\n",
      "[223]\tvalid's auc: 0.976066\n",
      "[224]\tvalid's auc: 0.976067\n",
      "[225]\tvalid's auc: 0.976067\n",
      "[226]\tvalid's auc: 0.976065\n",
      "[227]\tvalid's auc: 0.976063\n",
      "[228]\tvalid's auc: 0.976064\n",
      "[229]\tvalid's auc: 0.976077\n",
      "[230]\tvalid's auc: 0.976076\n",
      "[231]\tvalid's auc: 0.97608\n",
      "[232]\tvalid's auc: 0.976083\n",
      "[233]\tvalid's auc: 0.976088\n",
      "[234]\tvalid's auc: 0.976093\n",
      "[235]\tvalid's auc: 0.976112\n",
      "[236]\tvalid's auc: 0.976114\n",
      "[237]\tvalid's auc: 0.97611\n",
      "[238]\tvalid's auc: 0.976111\n",
      "[239]\tvalid's auc: 0.97611\n",
      "[240]\tvalid's auc: 0.976108\n",
      "[241]\tvalid's auc: 0.976108\n",
      "[242]\tvalid's auc: 0.976116\n",
      "[243]\tvalid's auc: 0.976118\n",
      "[244]\tvalid's auc: 0.976118\n",
      "[245]\tvalid's auc: 0.976127\n",
      "[246]\tvalid's auc: 0.976127\n",
      "[247]\tvalid's auc: 0.976128\n",
      "[248]\tvalid's auc: 0.976144\n",
      "[249]\tvalid's auc: 0.976149\n",
      "[250]\tvalid's auc: 0.976193\n",
      "[251]\tvalid's auc: 0.976212\n",
      "[252]\tvalid's auc: 0.976221\n",
      "[253]\tvalid's auc: 0.976221\n",
      "[254]\tvalid's auc: 0.976223\n",
      "[255]\tvalid's auc: 0.976231\n",
      "[256]\tvalid's auc: 0.976231\n",
      "[257]\tvalid's auc: 0.976229\n",
      "[258]\tvalid's auc: 0.976228\n",
      "[259]\tvalid's auc: 0.976237\n",
      "[260]\tvalid's auc: 0.976236\n",
      "[261]\tvalid's auc: 0.976208\n",
      "[262]\tvalid's auc: 0.97621\n",
      "[263]\tvalid's auc: 0.976233\n",
      "[264]\tvalid's auc: 0.976229\n",
      "[265]\tvalid's auc: 0.976231\n",
      "[266]\tvalid's auc: 0.976232\n",
      "[267]\tvalid's auc: 0.976228\n",
      "[268]\tvalid's auc: 0.97623\n",
      "[269]\tvalid's auc: 0.976227\n",
      "[270]\tvalid's auc: 0.976229\n",
      "[271]\tvalid's auc: 0.976242\n",
      "[272]\tvalid's auc: 0.976234\n",
      "[273]\tvalid's auc: 0.976235\n",
      "[274]\tvalid's auc: 0.976242\n",
      "[275]\tvalid's auc: 0.976242\n",
      "[276]\tvalid's auc: 0.97625\n",
      "[277]\tvalid's auc: 0.976248\n",
      "[278]\tvalid's auc: 0.97625\n",
      "[279]\tvalid's auc: 0.976254\n",
      "[280]\tvalid's auc: 0.976253\n",
      "[281]\tvalid's auc: 0.976253\n",
      "[282]\tvalid's auc: 0.976263\n",
      "[283]\tvalid's auc: 0.976285\n",
      "[284]\tvalid's auc: 0.976304\n",
      "[285]\tvalid's auc: 0.976314\n",
      "[286]\tvalid's auc: 0.976349\n",
      "[287]\tvalid's auc: 0.976345\n",
      "[288]\tvalid's auc: 0.976346\n",
      "[289]\tvalid's auc: 0.976348\n",
      "[290]\tvalid's auc: 0.97635\n",
      "[291]\tvalid's auc: 0.976349\n",
      "[292]\tvalid's auc: 0.976358\n",
      "[293]\tvalid's auc: 0.976366\n",
      "[294]\tvalid's auc: 0.976371\n",
      "[295]\tvalid's auc: 0.976364\n",
      "[296]\tvalid's auc: 0.976365\n",
      "[297]\tvalid's auc: 0.976364\n",
      "[298]\tvalid's auc: 0.976361\n",
      "[299]\tvalid's auc: 0.976357\n",
      "[300]\tvalid's auc: 0.976387\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid's auc: 0.976387\n"
     ]
    }
   ],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "params = {'metric':FIXED_PARAMS['metric'],\n",
    "             'objective':FIXED_PARAMS['objective']}\n",
    "model = lgb.train(params, train_data,                     \n",
    "                     valid_sets=[valid_data],\n",
    "                     num_boost_round=FIXED_PARAMS['num_boost_round'],\n",
    "                     early_stopping_rounds=FIXED_PARAMS['early_stopping_rounds'],\n",
    "                     valid_names=['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9763867119096838"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.best_score['valid']['auc']\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_submission_file(model, \"lightgbm_submission5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_catboost_model = catboost_model.fit(X_train, y_train,\n",
    "                                           cat_features=['branch_code_1X1H', \n",
    "                                                         'branch_code_30H5', 'branch_code_49BM',\n",
    "                                                        'branch_code_748L', 'branch_code_94KC', 'branch_code_9F9T',\n",
    "                                                        'branch_code_BOAS', 'branch_code_E5SW', 'branch_code_EU3L',\n",
    "                                                        'branch_code_O4JC', 'branch_code_O67J', 'branch_code_UAOD',\n",
    "                                                        'branch_code_X23B', 'branch_code_XX25', 'branch_code_ZFER',\n",
    "                                                         'occupation_category_code_56SI', \n",
    "                                                         'occupation_category_code_90QI',\n",
    "                                                        'occupation_category_code_AHH5', \n",
    "                                                         'occupation_category_code_JD7X',\n",
    "                                                        'occupation_category_code_L44T', \n",
    "                                                         'occupation_category_code_T4MS',\n",
    "                                                        'marital_status_D', 'marital_status_F', 'marital_status_M',\n",
    "                                                        'marital_status_P', 'marital_status_R', 'marital_status_S',\n",
    "                                                        'marital_status_U', 'marital_status_W','IsMale'],\n",
    "                                            eval_set=(X_valid, y_valid),\n",
    "                                            verbose=False\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
